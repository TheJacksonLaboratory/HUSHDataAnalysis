---
title: "Prednisone-association"
author: "Aaron Zhang"
date: "6/1/2018"
output: html_document
---

```{r setup}
knitr::opts_knit$set(root.dir = "~/git/HushToFhir/")
```

# Data:
UNC HUSH+ data about ~15,000 patients who visited hospitals for asthma treatment. The patient cohort was selected by ICD codes for asthma and asthma-related symptoms by collaborators at UNC. Therefore, in theory, all those patients should have some asthma-related issues. However, we are not provided with the list of ICD codes used for patient selection; we did discover that about 1/3 of them have ICD9/10 codes for asthma (see analysis).

The raw dataset contains 8 CSV files, including PATIENT_DIMENTION, PROVIDER_DIMENSION, VISIT_DIMENSION, OBSERVATION_FACT, OBSERVATION_FACT_GEOCODES, CODE_LOOKUP, CONCEPT_DIMENSION, MODIFIER_DIMENSION. This analysis utilizes three tables, PATIENT_DIMENSION for patient information (de-identified), VISIT_DIMENSION for encounter information, and OBSERVATION_FACT. The OBSERVATION_FACT table is the core and largest of this dataset.  It contains all kinds of records meshed together, lab tests, prescription, diagnosis, procedure, vital signs etc, totaling 54 million lines and 10 gigabytes.  

# Goal:
Our primary goal is to use this dataset to demonstrate how to semantically integrate lab tests with the LOINC to HPO mapping library. More specially, we hope to achieve the following goals:
I.   Convert LOINC-coded lab tests into HPO terms
II.  Identify HPO differential distribution among different patient groups, e.g. severe and non-severe asthma groups
III. Test whether the transformed data can be used for medical prediction with machine learning. 

# Analysis:

## load data
For Goal I, the dataset is too big and the task too complicated to implicate in R. Instead, we implicated the conversion in Java. Run the code in command line:
```{bash, ignore = TRUE, include = FALSE}
java --jar HushToFhir-1.0-SNAPSHOT-jar-with-dependencies.jar -l2h \                 # loinc to hpo transformation
-i /Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+/OBSERVATION_FACT.txt \  # input: all observations
-hpo /Users/zhangx/git/human-phenotype-ontology/src/ontology/hp.obo \               # hpo.obo is required
-loinc /Users/zhangx/Downloads/LOINC_2/LoincTableCore.csv \                         # LOINC table is required
-a /Users/zhangx/git/loinc2hpoAnnotation/Data/TSVSingleFile/annotations.tsv \       # loinc2hpo annotation map is                                                                                       # required
#-o /Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+/loinc2hpotransformation8-2-2018.txt # output transformed data
```

We also counted prednisone prescription times for each patient in Java. Run:
```{bash}
java HushToFhir-1.0-SNAPSHOT-jar-with-dependencies.jar -p \                                   # prednisone prescription count
-i /Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+/OBSERVATION_FACT.txt \            # input: all observations
-o /Users/zhangx/git/HushToFhir/data/patientOnPrednison.txt                                   # output patients on prednisone
```
The raw dataset is provided to us as 9 separate CSV files. We have imported them into a SQLite database for easy query. 
Note: import the patientOnPrednisone table to the SQLite database
```{sql connection="/Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+_UNC_JAX.sqlite"}
CREATE TABLE IF NOT EXISTS PatientOnPrednison ( 
 patient_num integer PRIMARY KEY, 
 prescrib_times integer 
)
```
Note: we have parsed the data in Java to select all diagnosis records (with ICD codes) and imported them to the database as a separate table.
```{bash}
java HushToFhir-1.0-SNAPSHOT-jar-with-dependencies.jar -icd \                                 # select ICD records
-i /Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+/OBSERVATION_FACT.txt \            # input: all observations
-o /Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+/ICD.txt                           # output: ICD records
```
schema for ICD (same as the OBSERVATION_FACT table)
```{sql connection="/Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+_UNC_JAX.sqlite"}
CREATE TABLE IF NOT EXISTS ICD(
  encounter_num INT,
  patient_num INT,
  concept_cd TEXT,
  provider_id TEXT,
  start_date NUM,
  modifier_cd TEXT,
  instance_num INT,
  valtype_cd TEXT,
  tval_char TEXT,
  nval_num REAL,
  valueflag_cd TEXT,
  quantity_num REAL,
  units_cd TEXT,
  end_date NUM,
  location_cd TEXT,
  observation_blob TEXT,
  confidence_num REAL,
  update_date NUM,
  download_date NUM,
  import_date NUM,
  sourcesystem_cd TEXT,
  upload_id INT,
  text_search_index TEXT,
  icd NUM
)
```
Note: we have calculated the loinc2hpo annotation statistics in Java
```{bash}
java HushToFhir-1.0-SNAPSHOT-jar-with-dependencies.jar -stat \                                  # statistics
-hpo /Users/zhangx/git/human-phenotype-ontology/src/ontology/hp.obo \                           # hpo.obo is required
-loinc /Users/zhangx/Downloads/LOINC_2/LoincTableCore.csv \                                     # LOINC table is required
-a /Users/zhangx/git/loinc2hpoAnnotation/Data/TSVSingleFile/annotations.tsv \                   # loinc2hpo annotation map is                                                                                                 # required
-o /Users/zhangx/git/HushToFhir/data/loincAnnotationstats8-2-2018.tsv                           # output transformed data
```


```{r}
#load R libraries
library(tidyverse)
library(scales)
library(RSQLite)
library(Rmpfr)
library(lubridate)
```

Connect to the database.
```{r}
db <- dbConnect(RSQLite::SQLite(), "/Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+_UNC_JAX.sqlite")
```
From the database, retrieve patient list
import prednisone prescription times for each patient (0 is no prednison was ever prescribed)
calculate the number of patient visits to hospitals from the database
  How do we count the number of hospital visits for each patient?
  It is impossible to get an accurate number, so we use the number of unique dates when a patient had an encounter to estimate the number of visits.
import loinc2hpo transformation
select the patients that were diagnosed with asthma ICD9/10 codes
import the ICD9 and ICD10 codes 
```{r}
patients <- dbGetQuery(db, "SELECT patient_num, birth_date, sex_cd FROM PATIENT_DIMENTION")
prednisonPrescribTimes <- read.csv("/Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+/patientPrednisonPrsbCount.txt", header = TRUE, sep = "\t");
# replace na with 0
prednisonPrescribTimes <- prednisonPrescribTimes %>% mutate(prscbCount = ifelse(is.na(prscbCount), 0, prscbCount))
visitCount <- dbGetQuery(db, "SELECT V.patient_num, count(distinct(O.start_date)) AS encounter_no_days FROM VISIT_DIMENSION AS V LEFT JOIN OBSERVATION_FACT AS O ON V.encounter_num = O.encounter_num AND V.patient_num = O.patient_num GROUP BY V.patient_num ORDER BY encounter_no_days DESC")
loinc2hpo <- read.csv("/Users/zhangx/Documents/HUSH+_UNC_JAX/Hush+UNC_JAX/HUSH+/loinc2hpotransformation8-2-2018.txt", header = TRUE, sep = "\t")

#select patient subset with ICD codes for asthma
patient_withAsthmaICD <- dbGetQuery(db, "SELECT DISTINCT(patient_num) FROM ICD WHERE icd LIKE 'ICD9:493%' OR icd LIKE 'ICD10:J45%'")
#select patient subset with Bronchospasm 
patientWithBronchospasm <- dbGetQuery(db, "SELECT DISTINCT(patient_num) FROM ICD WHERE icd LIKE 'ICD9:519%' OR icd LIKE 'ICD10:J98%'")
#select all diagnosis for patients with asthma
allICDCodesForPatientWithAsthma <- dbGetQuery(db, "SELECT icd, COUNT(DISTINCT(patient_num)) AS count FROM ICD WHERE patient_num IN (SELECT DISTINCT(patient_num) FROM ICD WHERE icd LIKE 'ICD9:493%' OR icd LIKE 'ICD10:J45%') GROUP BY icd ORDER BY count DESC ;")
#select all diagnosis for patients without asthma
allICDCodesForPatientWithoutAsthma <- dbGetQuery(db, "SELECT icd, COUNT(DISTINCT(patient_num)) AS count FROM ICD WHERE patient_num NOT IN (SELECT DISTINCT(patient_num) FROM ICD WHERE icd LIKE 'ICD9:493%' OR icd LIKE 'ICD10:J45%') GROUP BY icd ORDER BY count DESC ;")
patient_withDiabetes <- dbGetQuery(db, "SELECT DISTINCT(patient_num) FROM ICD WHERE icd LIKE 'ICD9:250%' OR icd LIKE 'ICD10:E11%'") %>%  mutate(withDiabeteICDCode = "Y")
patient_withChronicLiverDamage <- dbGetQuery(db, "SELECT DISTINCT(patient_num) FROM ICD WHERE icd = 'ICD10:N18' OR icd = 'ICD9:585'") %>% mutate(withChronicLiverDamageICDCode = "Y")
#the following query is too broad. The vast majority of patients are selected
#patient_withRepiratorySymptomsAndBreezingIssues <- dbGetQuery(db, "SELECT DISTINCT(patient_num) FROM ICD WHERE icd = 'J45' OR icd = 'ICD10:R06' OR icd = 'ICD9:786' OR icd = 'ICD9:519'") %>% mutate(withRepiratorySymptomsAndBreezingIssues = "Y")
patient_withBreazingDifficulties <- dbGetQuery(db, "SELECT DISTINCT(patient_num) FROM OBSERVATION_FACT where concept_cd LIKE 'ICD10:R06.2%' OR concept_cd LIKE 'ICD10:R06.02' OR concept_cd LIKE 'ICD10:J98.01%' OR concept_cd LIKE 'ICD9:519.11%' OR concept_cd LIKE 'ICD9:786.07' ") %>% mutate(withBreathingDifficuities = "Y")
patient_withAcuteAsthma <- dbGetQuery(db, "SELECT DISTINCT(patient_num) FROM OBSERVATION_FACT where concept_cd LIKE 'ICD10:J45._1%' OR concept_cd LIKE 'ICD10:J45._2%' OR concept_cd LIKE 'ICD10:J45.90%'  OR concept_cd LIKE 'ICD9:493._1%' OR concept_cd LIKE 'ICD9:493._2' ") %>% mutate(withAcuteAsthma = "Y")

icd9_3_digit_codes <- read.csv("/Users/zhangx/git/HushToFhir/src/main/resources/icd9_ThreeDigitCodes.tsv", sep = "\t", header = TRUE, stringsAsFactors = FALSE, as.is = "character")
icd10_3_digit_codes <- read.csv("/Users/zhangx/git/HushToFhir/src/main/resources/icd10cm_ThreeDigitCodes.tsv", sep = "\t", header = TRUE, stringsAsFactors = FALSE, as.is = "character")
loinc2hpoAnnotationFile <- read.csv("/Users/zhangx/git/loinc2hpoAnnotation/Data/TSVSingleFile/annotations.tsv", sep = "\t", stringsAsFactors = FALSE, header = TRUE)
loincAnnotationStat <- read.csv("/Users/zhangx/git/HushToFhir/data/loincAnnotationstats8-2-2018.tsv", header = TRUE, sep = "\t")
```

define a helper function that handles the negation information in loinc2hpo mapping library
```{r}
boolString <- function(x) {
  newvec <- vector(mode = "character")
  for (i in 1:length(x)) {
    if (x[i] == "true") {
      newvec[i] <- "NOT "   # if an HPO is negated (true), the string for the HPO should be prefixed with "NOT "
    } else {
      newvec[i] <- ""       # otherwise, no prefix
    }
  }
  return (newvec)
}
```

Combine ICD9 and ICD10 code lists (just use the first three digits), look at what diagnosis codes do asthma patients have. From this analysis, we got the impression that many asthma patients seemed to suffer from diabetes(hypertension, lipid metabolism disorders) and liver issues (combined from other analysis).   
```{r}
icd_3_digit_code_annotation <- 
  icd9_3_digit_codes %>% 
      mutate(icd = paste("ICD9", icd9code, sep = ":")) %>% 
      rename(descr = icd9descr) %>% 
      select(icd, descr) %>%
    bind_rows(
    icd10_3_digit_codes %>% 
      mutate(icd = paste("ICD10", icd10code, sep = ":")) %>% 
      rename(descr = icd10descr) %>% 
      select(icd, descr) 
    )

allDiagnosisCodesForAsthmaPatients <- allICDCodesForPatientWithAsthma %>% left_join(icd_3_digit_code_annotation) %>% select(icd, count, descr)
allDiagnosisCodesForNonAsthmaPatients <- allICDCodesForPatientWithoutAsthma %>% left_join(icd_3_digit_code_annotation) %>% select(icd, count, descr)
head(allDiagnosisCodesForAsthmaPatients, n = 40)
```
```{r}
write.table(allDiagnosisCodesForAsthmaPatients, "/Users/zhangx/git/HushToFhir/data/allDiagnosisCodesForAsthmaPatients.tsv", sep = "\t", quote = FALSE)
```


## calculate some statistics for the loinc2hpo conversion
In this section, we will calculate some simple statistics about the LOINC to HPO mapping library and the transformed data from lab tests. Our goal is to determine whether we have successfully integrate lab tests. 

### determine how many LOINC code are mapped to each HPO term in the mapping library
```{r}

loinc2hpoAnnotationFile %>% select(loincId, loincScale) %>% distinct() %>% 
  group_by(loincScale) %>%
  summarise(counts = n()) %>% 
  arrange(desc(counts)) %>%
  print()
  
#loincAnnotationStat <- loinc2hpoAnnotationFile %>% select(loincId, hpoTermId) %>% distinct() %>% group_by(hpoTermId) %>%
#  summarise(counts = n()) %>% arrange(desc(counts))
#mean(loincAnnotationStat$counts)
#quantile(loincAnnotationStat$counts)
#sum(loincAnnotationStat$counts >=2) / length(loincAnnotationStat$counts)

loincAnnotationStat <- loincAnnotationStat %>% mutate(hpo = make.names(as.character(hpo)), loincMappedTo = loincCounts) %>% select(hpo, loincMappedTo)
no.LOINC.per.HPO_ave = mean(loincAnnotationStat$loincMappedTo)
no.LOINC.per.HPO_q = quantile(loincAnnotationStat$loincMappedTo)
fraction.multi.LOINC.per.HPO = sum(loincAnnotationStat$loincMappedTo >=2) / length(loincAnnotationStat$loincMappedTo)
```
```{r}
print(paste("average number of LOINC code per HPO term: ", round(no.LOINC.per.HPO_ave, 1)))
print("number of LOINC code per HPO term quantile: ")
print(no.LOINC.per.HPO_q)
print(paste("fraction of HPO terms mapped from multiple LOINC codes: ", round(fraction.multi.LOINC.per.HPO, 3)))
```
Since we are mapping multiple LOINC tests into one HPO term, we have achieved semantic integration of lab tests (at least in theory!). 

### determine the percentage of lab tests that can be successfully mapped to an HPO with our mapping library
```{r}
successRate <- sum(loinc2hpo$mapFailed == "false")/nrow(loinc2hpo)
print(paste("loinc2hpo conversion rate: ", round(successRate, 3) * 100, "%", sep = ""))
```
We have mapped nearly 70% of all lab tests into HPO, which is pretty good. Since we are still expanding our LOINC to HPO mapping library, we will be able to further improve the success rate in future.

Next, create a plot to show the success rate.
```{r}
loinc2hpo %>% select(mapFailed, encounter_num, patient_num, concept_cd, start_date) %>% group_by(mapFailed) %>% summarise(counts = n()) %>%
  ggplot() + geom_bar(aes(x = 1, y = counts / sum(counts), fill = mapFailed), stat = "identity",   color = "black", size = 0.5) + coord_polar(theta = "y") +
  scale_fill_manual(name = "lab test to HPO\nconversion", breaks = c("false", "true"), labels = c("success", "fail"), values = c("white", "gray")) + 
  xlab("") + ylab("") + theme_bw() +
  theme(panel.grid = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(), legend.position = "none", legend.background = element_blank(), panel.border = element_blank(), legend.text = element_text(size = 8), legend.title = element_blank(), legend.key.size = unit(1, "line"), axis.title = element_text(size = 8)) 
```

```{r}
ggsave("./data/images/Hush lab test to HPO conversion.png", width = 2, height = 2)
```

### count the number of total HPO mapped to each patient, and total of unique HPO mapped to each HPO
```{r}
hpoTermCountsWithDuplicationPerPatient <- loinc2hpo %>% select(mapFailed, patient_num, hpoTerm) %>% 
  filter(mapFailed == "false") %>% 
  group_by(patient_num) %>% summarise(counts = n())  %>% ungroup()

no.HPOperPatient = sum(hpoTermCountsWithDuplicationPerPatient$counts) / nrow(patients)
print(paste("average no. of HPO terms per patient: ", round(no.HPOperPatient, 1), sep = ""))

  ggplot(hpoTermCountsWithDuplicationPerPatient) + geom_histogram(aes(counts), binwidth = 500) + xlab("no. of HPO terms\nper patient") + ylab("patient Counts") + scale_x_continuous(limits = c(-500, 8000), breaks = seq(0, 8000, by = 2000)) + 
  theme_bw() + theme(panel.grid = element_blank(), axis.title = element_text(size = 10), axis.text = element_text(size = 8), axis.ticks = element_line(size = 0.1), axis.ticks.length = unit(0.1, "line"), panel.border = element_rect(size = 0.25), panel.background = element_blank(), axis.title.y = element_text(vjust = -2), axis.title.x= element_text(vjust = 2))
ggsave("./data/images/HPO term counts for each patient.png", width = 0.8, height = 0.8 )

uniqueHPOperPatient <- loinc2hpo %>% select(mapFailed, patient_num, hpoTerm) %>% 
  filter(mapFailed == "false") %>%
  distinct() %>%
  group_by(patient_num) %>% 
  summarise(counts = n()) %>%ungroup()
no.uniqueHPOperPatient = sum(uniqueHPOperPatient$counts) / nrow(patients)
print(paste("average no. of unique HPO terms per patient: ", round(no.uniqueHPOperPatient, 1), sep = ""))

  ggplot(uniqueHPOperPatient) + geom_histogram(aes(counts), binwidth = 10, fill = "white", color = "black", size = 0.75) + xlab("number of unique phenotypes for each patient") + ylab("patient Counts") +
  theme_bw() + theme(panel.grid = element_blank(), axis.title = element_text(size = 8), axis.text = element_text(size = 8), axis.ticks = element_line(size = 0.1), axis.ticks.length = unit(0.1, "line"), panel.border = element_rect(size = 0.25), panel.background = element_blank(), axis.title.y = element_text(vjust = 0), axis.title.x= element_text(vjust = 1))
ggsave("./data/images/unique HPO term counts for each patient.png", width = 3, height = 2)

aveKindsOfLoincs <- loinc2hpo %>% select(mapFailed, patient_num, concept_cd, hpoTerm) %>% 
  filter(mapFailed == "false") %>%
  select(-patient_num) %>%
  distinct() %>%
  group_by(hpoTerm) %>% 
  summarise(counts = n()) %>%ungroup()
no.aveKindsOfLoincsPerHPO = mean(aveKindsOfLoincs$counts)
print(paste("average no. of distinct LOINC per HPO term: ", round(no.aveKindsOfLoincsPerHPO, 1), sep = ""))
```
The results are pretty impressive. We have assigned ~500 HPO terms for each patient on average. Given that it is entirelly software-driven, we have made it possible to automatically phenotype patients from EHR at a large scale, which was still quite difficult to do. Among the ~500 HPO terms, ~50 of them are unique, which is expected because a patient are usually repeated given the same kind of lab test over time. 


### determine how many LOINC codes are collapsed to each HPO term
We have shown that in our mapping library, we mapped multiple LOINC codes into one HPO term (8.7 LOINC per HPO term on average). Here, we will determine in a real-world dataset, how many LOINC-coded lab tests are collapsed to the same HPO terms. 
```{r}
loincAggregated <- loinc2hpo %>%
  filter(mapFailed == "false") %>%
  select(concept_cd, hpoTerm) %>%
  distinct() %>%
  group_by(hpoTerm) %>%
  mutate(loincAggrgtdFrom = n()) %>%
  ungroup() %>%
  mutate(hpo = make.names(as.character(hpoTerm))) %>%
  select(hpo, loincAggrgtdFrom) %>%
  distinct()
head(loincAggregated, n = 20)

aggrgedFromOneLOINC <- sum(loincAggregated$loincAggrgtdFrom==1)
aggrgedFromTwoLOINC <- sum(loincAggregated$loincAggrgtdFrom==2)
aggrgedFromThreeAndMoreLOINC <- sum(loincAggregated$loincAggrgtdFrom==3)
data.frame(aggrgtedFrom = factor(c("1", "2", ">3"), levels = c("1", "2", ">3")), count = c(aggrgedFromOneLOINC, aggrgedFromTwoLOINC, aggrgedFromThreeAndMoreLOINC)) %>% 

  ggplot() + geom_bar(aes(x = 1, y = count, fill = aggrgtedFrom), stat = "identity", color = "black", size = 0.5) + coord_polar(theta = "y") +
  scale_fill_manual(name = "aggregated from # distinct LOINC tests", breaks = c("1", "2", ">3"),  values = c("white", "gray75", "gray50")) + 
  xlab("") + ylab("") + theme_bw() +
  theme(panel.grid = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(), legend.position = "none", legend.background = element_blank(), panel.border = element_blank(), legend.text = element_text(size = 8), legend.title = element_blank(), legend.key.size = unit(1, "line"), axis.title = element_text(size = 8))
ggsave("./data/images/aggregatedfrom.png", width = 2, height = 2)
```
The result shows that multiple kinds of lab tests are collapsed into one HPO term in real world data, indicating we have achieved our goal of semantic integration of lab tests! 

### determine how many times a patient is mapped to a hpo term
We have shown that a patient is mapped to the same HPO terms multiple times. Here, we will create a list of the number of times a patient is assigned to each HPO term. 
```{r}
patientTermMapFreq <- loinc2hpo %>% 
  filter(mapFailed == "false") %>%
  select(patient_num, isNegated, hpoTerm) %>% #7,636,885 lines of records
  #count()
  group_by(patient_num, isNegated, hpoTerm) %>% # for each patient and each term, count how many times the term is diagnosed with a test
  summarise(hpoTermFreq = n()) %>%
  ungroup() %>% #726,747 lines of records ---->>> a patient is frequenctly mapped to the same HPO term!
  #count()
  mutate(hpoTerm = make.names(hpoTerm))
head(patientTermMapFreq)
```

## join tables together
We will join multiple tables created above together to do more interesting analysis. The join is centered on patients--for each patient, we indicate what HPO terms are assigned to them and how many times, when is the birthday, the first and last hospital visit date, whether they have ICD diagnosis codes for asthma, diabetes and chronic liver damage, and how many times they were prescribed with prednisone, a steriod drug that is typcially prescribed to severe asthma patients. 

In doing the joining, skip patients without any HPO terms and skip HPO terms for unknown patients.
```{r}
patient_withAsthmaICD <- patient_withAsthmaICD %>% mutate(withAsthmaICDCode = "Y")
patient_lastFirstVisit <- loinc2hpo %>% select(patient_num, start_date) %>% mutate(start_date = as.Date(start_date)) %>% group_by(patient_num) %>% summarise(lastVisit = max(start_date), firstVisit = min(start_date))

combined <- patients %>%
  inner_join(patientTermMapFreq, by = "patient_num") %>%
  left_join(visitCount, by = "patient_num") %>%
  left_join(prednisonPrescribTimes, by = "patient_num") %>%
  left_join(patient_withAsthmaICD, by = "patient_num") %>%
  left_join(patient_withDiabetes, by = "patient_num") %>% # add diabete label
  left_join(patient_withChronicLiverDamage, by = "patient_num") %>% # add chronic liver damage label
  left_join(patient_lastFirstVisit, by = "patient_num") %>%
  mutate(prscbCount = ifelse(is.na(prscbCount), 0, prscbCount)) %>%
  mutate(withAsthmaICDCode = ifelse(is.na(withAsthmaICDCode), "N", "Y")) %>%
  mutate(withDiabeteICDCode = ifelse(is.na(withDiabeteICDCode), "N", "Y")) %>%
  mutate(withChronicLiverDamageICDCode = ifelse(is.na(withChronicLiverDamageICDCode), "N", "Y")) %>%
  mutate(hpoTerm = make.names(hpoTerm))
nrow(combined)
```

export the combined table for machine learning
```{r}
#spread it to a matrix for machine learning
df4ML <- combined %>%
  filter(isNegated == "false") %>% # ignore records that were not converted into HPO
  spread(key = hpoTerm, value = hpoTermFreq, fill = 0) %>%
  mutate(age = round(as.duration(interval(birth_date, lastVisit))/dyears(1), 1)) %>%
  mutate(record_duration = round(as.duration(interval(firstVisit, lastVisit))/dyears(1), 1)) %>%
  select(-c(birth_date, firstVisit, lastVisit, isNegated)) %>%
  select(patient_num, age, record_duration, sex_cd, everything()) %>%
  select(-prscbCount, prscbCount)
dim(df4ML)
colnames(df4ML)
```
export the data frame for machine learning
```{r}
write.csv(df4ML, "./data/Hush+_data_matrix.csv", quote = FALSE, row.names = FALSE)
```

## identify HPO terms that are associated with frequent prednisone prescription
We divided patients into severe and nonsevere asthma groups based on the number of prednisone prescription. For each HPO, we hope to test whether it is associated with asthma severity. Two significance tests are considered, Chi-squared test and Fisher's exact test. We choose Fisher's test because it can handle small sample size. 

### count severe and non-severe patients among those that are assigned to each HPO term
As a QC parameter, we calculated the number of hospital visits. Patients visited hospital less frequently have smaller chances to be tested. Therefore, some patients are ignored if their visit times (actually, number of days visiting a hospital) were below a threshold. 
We defined a tunable threshold for prednisone prescription times to classify patients into severe and non-severe groups.  
We also defined a threshold for the number of times an HPO has to occur before we call a patient "positive" for certain phenotypic abnormality.
All three thresholds are set expirically.  
```{r}
VISITTIMES_THRESHOLD = 10  
SEVERITY_THRESHOLD = 4
TERMFREQ_THRESHOLD = 5
  
patientConditionalCounts <- function(data = combined, hasAsthma, hasDiabetes, hasChronicLiverDamages) {
  
  #ASTHMA_CONDITION = ifelse(hasAsthma, "Y", "N")
  #DIABETES_CONDITION = ifelse(hasDiabetes, "Y", "N")
  #CHRONIC_LIVER_DAMAGES_CONDITION = ifelse(hasChronicLiverDamages, "Y", "N")
  #ASTHMA_CONDITION = c("Y", "N")
  #DIABETES_CONDITION = c("Y", "N")
  #CHRONIC_LIVER_DAMAGES_CONDITION = c("Y", "N")
  if (missing(hasAsthma)) {
    ASTHMA_CONDITION <- c("Y", "N")
  } else if (hasAsthma) {
    ASTHMA_CONDITION <- c("Y")
  } else {
    ASTHMA_CONDITION <- c("N")
  }
  
  if (missing(hasDiabetes)) {
    DIABETES_CONDITION <- c("Y", "N")
  } else if (hasDiabetes) {
    DIABETES_CONDITION <- c("Y")
  } else {
    DIABETES_CONDITION <- c("N")
  }
  
  if (missing(hasChronicLiverDamages)) {
    CHRONIC_LIVER_DAMAGES_CONDITION <- c("Y", "N")
  } else if (hasChronicLiverDamages) {
    CHRONIC_LIVER_DAMAGES_CONDITION <- c("Y")
  } else {
    CHRONIC_LIVER_DAMAGES_CONDITION <- c("N")
  }
  #filters <- list(ASTHMA_CONDITION = vector(), 
  #                DIABETES_CONDITION = vector(), 
  #                CHRONIC_LIVER_DAMAGES_CONDITION = vector())
  
  patientsCounts <- data %>% 
  filter(encounter_no_days >= VISITTIMES_THRESHOLD) %>% #ignore patients that only occationally visited hospitals
  filter(is.element(withAsthmaICDCode, ASTHMA_CONDITION)) %>% #ignore patients that is not diagnosed with asthma
  filter(is.element(withDiabeteICDCode, DIABETES_CONDITION)) %>% #ignore patients that have been diagnosed with diabetes
  filter(is.element(withChronicLiverDamageICDCode, CHRONIC_LIVER_DAMAGES_CONDITION)) %>% # ignore patients that have been diagnosed with chronic liver damage
  filter(hpoTermFreq >= TERMFREQ_THRESHOLD) %>%
  mutate(severity = ifelse(prscbCount > SEVERITY_THRESHOLD, "severe", "nonSevere")) %>%
  group_by(isNegated, hpoTerm, severity) %>%
  summarise(count = n()) %>%
  spread(key = severity, value = count, fill = 0) %>%
  ungroup() %>%
  mutate(hpo = paste(boolString(isNegated), hpoTerm, sep = "")) %>%
  select(hpo, nonSevere, severe)
  
  # Calculate population distribution
  populationCounts <- combined %>%
  filter(is.element(withAsthmaICDCode, ASTHMA_CONDITION)) %>%
  filter(is.element(withDiabeteICDCode, DIABETES_CONDITION)) %>%
  filter(is.element(withChronicLiverDamageICDCode, CHRONIC_LIVER_DAMAGES_CONDITION)) %>%
  select(patient_num, prscbCount) %>% distinct() %>% mutate(severity = ifelse(prscbCount >= SEVERITY_THRESHOLD, "severity", "nonSevere")) %>% select(-prscbCount) %>% group_by(severity) %>% summarise(count = n())
  
  return(list(patientsCounts, populationCounts))
}
  
noAsthmaNoDiabetesNoCLD <- patientConditionalCounts(combined, hasAsthma = FALSE, hasDiabetes = FALSE, hasChronicLiverDamages = FALSE)
hasAsthmaNoDiabetesNoCLD <- patientConditionalCounts(combined, hasAsthma = TRUE, hasDiabetes = FALSE, hasChronicLiverDamages = FALSE)

noAsthma <- patientConditionalCounts(combined, hasAsthma = FALSE)
hasAsthma <- patientConditionalCounts(combined, hasAsthma = TRUE)
```

### statistical testing for HPO association with asthma severity
For each HPO term, we have calculated how many patients assigned to this term were classified as "severe" patients and "non-severe" patients. We could also calculate how many patients not assigned to the HPO term were classified as "severe" and "non-severe" patients. Therefore, we can do a significance test to determine whether HPO term and asthma severity is associated. 

We tested chi-squared test first, but decided to use Fisher's exact test because it handles small sample sizes better. 

#### define a few functions to compute the p-value using chisq or fisher's exact test
```{r}
# x is patient counts with a certain hpo term, divided into noPrednison or onPrednisone
# Y is patient counts among all patients, divided into non-severe and severe groups. The function will use those value to calculate patient counts not belonging to x
pValueChisq <- function(x, Y) {
  M <- as.matrix(rbind(as.integer(x[c(2,3)]), Y))
  M[2,] <- M[2,] - M[1,]
  return (chisq.test(M)[[3]])
}

testChisq <- function(x, Y) {
  M <- as.matrix(rbind(as.integer(x[c(2,3)]), Y))
  M[2,] <- M[2,] - M[1,]
  return (chisq.test(M))
}

pValueFisher <- function(x, Y) {
  M <- as.matrix(rbind(as.integer(x[c(2,3)]), Y))
  M[2,] <- M[2,] - M[1,]
  return (fisher.test(M)[[1]])
}

testFisher <- function(x, Y) {
  M <- as.matrix(rbind(as.integer(x[c(2,3)]), Y))
  M[2,] <- M[2,] - M[1,]
  return (fisher.test(M))
}

# this function is similar to chisq test but it is a fitness test
pValueChisqFitness <- function(x, Y) {
  p <- Y/sum(Y)
  return (chisq.test(as.integer(x[c(2,3)]), y = NULL, p)[[3]])
}
```

#### calculate the Fisher's exact test p value for all hpo terms and order by p
```{r}
outcome <- function(patientCombinedCounts, populationCount) {
  pValVec = rep(-1, nrow(patientCombinedCounts))
  #pValFlag = rep(0, nrow(patientCombinedCounts))
  for (i in 1:nrow(patientCombinedCounts)) {
    #print(i)
    #print(patientCombinedCounts[i,])
    #print(populationCount$count)
    #pValVec[i] <- pValueChisq(unlist(patientCombinedCounts[i,]), populationCount$count)
    #result <- testChisq(unlist(patientCombinedCounts[i,]), populationCount$count) #when using chisq test
    #pValVec[i] = result[[3]]
    #pValFlag[i] = sum(result$expected <= 5) # p value approachmation could be incorrect when expected value is less than 5
    result <- testFisher(unlist(patientCombinedCounts[i,]), populationCount$count) # when using fisher test
    pValVec[i] = result[[1]]
  }
  patientCombinedCounts$pVal <- pValVec
  #patientCombinedCounts$pFlag <- pValFlag
  return( patientCombinedCounts %>% 
    #rename(hpo = groupName) %>%
    mutate(`notSeverePatientNo(%)` = paste(nonSevere, "[", round(100 * nonSevere/populationCount$count[1], 1), "]", sep = "")) %>%
    mutate(nonSeverePercent = nonSevere/populationCount$count[1]) %>%
    mutate(`severePatientNo(%)` = paste(severe, "[", round(100 * severe/populationCount$count[2], 1), "]", sep = "")) %>%
    mutate(severePercent = severe/populationCount$count[2]) %>%
    filter(!startsWith(hpo, "NOT")) %>% 
    left_join(loincAggregated) %>%
    left_join(loincAnnotationStat) %>%
    select(hpo, mappedTo = loincMappedTo, aggrgtdFrom = loincAggrgtdFrom, `notSeverePatientNo(%)`, nonSeverePercent, `severePatientNo(%)`, severePercent, pVal) %>% 
    arrange(pVal))
}
```
```{r}
noasthmaNoDiabetesNoLiverDamage <- outcome(noAsthmaNoDiabetesNoCLD[[1]], noAsthmaNoDiabetesNoCLD[[2]])
noasthmaNoDiabetesNoLiverDamage_display <- noasthmaNoDiabetesNoLiverDamage %>% select(-nonSeverePercent, -severePercent)
asthmaNoDiabetesNoLiverDamage <- outcome(hasAsthmaNoDiabetesNoCLD[[1]], hasAsthmaNoDiabetesNoCLD[[2]])
asthmaNoDiabetesNoLiverDamage %>% select(-nonSeverePercent, -severePercent) %>% head(n = 10)
```

```{r}
noasthmaTerms <- outcome(noAsthma[[1]], noAsthma[[2]])
View(noasthmaTerms)
asthmaTerms <- outcome(hasAsthma[[1]], hasAsthma[[2]])
View(asthmaTerms)
```


From the group of patients diagnosed with asthma but not diabetes or chronic liver damages, 

save data
```{r}
write.csv(noasthmaNoDiabetesNoLiverDamage, "./data/patientCombinedCounts_noasthmaNoDiabetesNoLiverDamage.csv", quote = FALSE, row.names = FALSE)
write.csv(asthmaNoDiabetesNoLiverDamage, "./data/patientCombinedCounts_asthmaNodiabetesNoLiverDamage.csv", quote = FALSE, row.names = FALSE)
```

### For patients with asthma and without asthma, determine the ratio of likelihood to be severe asthma among patients having a HPO term vs not having a HPO term among
As one can see from the table, most HPO terms increase patients' likelihood to be severe asthma, indicating that many HPO terms might be only relate to asthma severity because they induce the phenotypic abnormalities (drug adverse effect)
```{r}
joined_data <- asthmaNoDiabetesNoLiverDamage %>% mutate(foldchange_asthma = severePercent/nonSeverePercent, significe_asthma = ifelse(pVal > 0.001, "N", "Y")) %>% select(hpo, foldchange_asthma, significe_asthma) %>% full_join(
  noasthmaNoDiabetesNoLiverDamage  %>% mutate(foldchange_no_asthma = severePercent/nonSeverePercent, significance_no_asthma = ifelse(pVal > 0.001, "N", "Y")) %>% select(hpo, foldchange_no_asthma, significance_no_asthma))

head(joined_data, n = 40)
```

Plot the relationship of ratios among patients with asthma and without asthma
```{r}
significance_group <- c("asthma group", "non-asthma group", "both group", "neither group")
significance_level <- c("asthma group", "non-asthma group", "both group", "neither group")

joined_data %>% na.omit() %>%  
  mutate(significance = ifelse(significe_asthma == "Y" & significance_no_asthma == "N", significance_group[1], ifelse(significe_asthma == "N" & significance_no_asthma == "Y", significance_group[2], ifelse(significe_asthma == "Y" & significance_no_asthma == "Y", significance_group[3], significance_group[4])))) %>% 
  mutate(tolabel = ifelse(significance == significance_group[1], hpo, ifelse(foldchange_asthma/foldchange_no_asthma  < 0.25 & significance != significance_group[4], hpo, "")))%>%
  ggplot() + geom_point(aes(x = foldchange_no_asthma, y = foldchange_asthma, shape = factor(significance, levels = significance_level), color = factor(significance, levels = significance_level), size = factor(significance, levels = significance_level))) + geom_text(aes(x = foldchange_no_asthma, y = foldchange_asthma, label = ""), size = 3, vjust = -1, hjust = -0.05) + coord_fixed(ratio = 1) + 
  scale_shape_manual(name = "", values = c(3, 4, 18, 16)) + scale_color_manual(name = "", values=c("red",  "blue", "orange", "black")) + scale_size_manual(name = "", values=c(3, 3, 2, 1)) +  xlab("HPO-dependent odds raio of being severe -asthma") + ylab("HPO-dependent odds raio of being severe +asthma") + theme_bw() + theme(panel.grid = element_blank(), legend.position = "none", legend.background = element_blank()) + geom_abline(intercept = 0, slope = 1, size = 0.5, color = "gray") + scale_y_continuous(limits = c(0, 50)) + scale_x_continuous(limits = c(0, 50))

joined_data %>% na.omit() %>%  
  mutate(significance = ifelse(significe_asthma == "Y" & significance_no_asthma == "N", significance_group[1], ifelse(significe_asthma == "N" & significance_no_asthma == "Y", significance_group[2], ifelse(significe_asthma == "Y" & significance_no_asthma == "Y", significance_group[3], significance_group[4])))) %>% 
  mutate(tolabel = ifelse(significance == significance_group[1], hpo, ifelse(foldchange_asthma/foldchange_no_asthma  < 0.25 & significance != significance_group[4], hpo, "")))%>%
  ggplot() + geom_point(aes(x = foldchange_no_asthma, y = foldchange_asthma, shape = factor(significance, levels = significance_level), color = factor(significance, levels = significance_level), size = factor(significance, levels = significance_level))) + 
  geom_text(aes(x = foldchange_no_asthma, y = foldchange_asthma, label = tolabel), size = 4, vjust = -1, hjust = -0.05) + coord_fixed(ratio = 1) + 
  scale_shape_manual(name = "significance", values = c(3, 4, 18, 16)) + scale_color_manual(name = "significance", values=c("red",  "blue", "orange", "black")) + scale_size_manual(name = "significance", values=c(3, 3, 2, 1)) +  xlab("HPO-dependent odds raio of being severe -asthma") + ylab("HPO-dependent odds raio of being severe +asthma") + theme_bw() + 
  theme(panel.grid = element_blank(), legend.position = c(0.2, 0.85), legend.background = element_blank(), axis.text = element_text(size = 8), axis.title = element_text(size = 10), panel.border = element_rect(size = 1), legend.text = element_text(size = 10), legend.title = element_text(size = 10)) + geom_abline(intercept = 0, slope = 1, size = 0.5, color = "gray") + scale_y_continuous(limits = c(0, 10)) + scale_x_continuous(limits = c(0, 10))
```

Test Logistic Regression for determining the HPO terms associated with asthma severity
```{r}
df_glm <- df4ML %>% filter(encounter_no_days >= VISITTIMES_THRESHOLD) %>% # still filter out patients that visited hospital infrequently 
    distinct()

glm_X = df_glm %>%  
  mutate(isSevere = as.factor(ifelse(prscbCount >= SEVERITY_THRESHOLD, 1, 0))) %>%
  mutate(withAsthmaICDCode = as.factor(ifelse(withAsthmaICDCode == "Y", 1, 0))) %>%
  select(patient_num, encounter_no_days, prscbCount, isSevere, withAsthmaICDCode)

# severity classification
severity_class <- function(x) {
  y <- vector(mode = "numeric", length = length(x))
  y = case_when(
    x <= 1 ~ 0,
    x >1 & x <= 5 ~ 1,
    x > 5 & x < 10 ~ 2,
    x > 10 ~ 3
  )
  return (y)
}

#glm_X = df_glm %>%  
#  mutate(isSevere = as.factor(severity_class(prscbCount))) %>%
#  mutate(withAsthmaICDCode = as.factor(ifelse(withAsthmaICDCode == "Y", 1, 0))) %>%
#  select(patient_num, encounter_no_days, prscbCount, isSevere, withAsthmaICDCode)


glm_Y = df_glm %>% select(9:133)
library(caret)
low_variance <- nearZeroVar(glm_Y)
glm_Y <- glm_Y[,-low_variance]  

glm_p_value <- function(hpo, x = glm_X) {
  target <- as.factor(ifelse(hpo >= 3, 1, ifelse(hpo == 0, 0, 0.5)))
  df <- cbind(x, hpo, target) %>% filter(target == 0 | target == 1)
  df_severe <- df %>% filter(isSevere == 1)
  df_nonSevere <- df %>% filter(isSevere == 0)
  sampled_rows <- sample(1:nrow(df_nonSevere), nrow(df_severe))
  df <- rbind(df_severe, df_nonSevere[sampled_rows,])
  glmmodel <- glm(target ~ isSevere + withAsthmaICDCode, data = df, family = binomial(link = "logit"), maxit = 50)
  return (summary(glmmodel))
}

set.seed(757)
tests <- glm_Y %>% map(glm_p_value) %>% map(~.$coefficients)

confid.int <- function(mean, sd, critical.value = 1.98, FUN = exp) {
  result <- vector(mode = "character", length = length(mean))
  lower <- mean - critical.value * sd
  upper <- mean + critical.value * sd
  lower.transf <- FUN(lower)
  upper.transf <- FUN(upper)
  for (i in 1 : length(mean)){
    result[i] <- str_c(c("[", as.character(round(lower.transf[i], 2)), "~", as.character(round(upper.transf[i], 2)), "]"), sep = "", collapse = "")
  }
  return (result)
}

result <- data.frame(hpo = names(tests), 
                           estimate.isSevere = round(exp(tests %>% map_dbl(~.[2, 1])), 2),
                           ci.isSevere = confid.int(tests %>% map_dbl(~.[2, 1]), 
                                                    tests %>% map_dbl(~.[2, 2])),
                           p.isSevere = tests %>% map_dbl(~.[2,4]),
                           estimate.withAsthmaICDCode = round(exp(tests %>% map_dbl(~.[3,1])), 2),
                           ci.withAsthmaICDCode = confid.int(tests %>% map_dbl(~.[3, 1]), 
                                                    tests %>% map_dbl(~.[3, 2])),
                           p.withAsthmaICDCode = tests %>% map_dbl(~.[3,4]))
  
result %>% arrange(-estimate.withAsthmaICDCode) %>% filter(p.isSevere < 1, p.withAsthmaICDCode < 1) %>% View()
```

The above test has a little unstability due to the fact that we have to sample the control popultion to get the p value. below the test is more rigious and the result is pretty similar. 
Note: below we use acute asthma patients only. No sampling
```{r}
df_glm <- df4ML %>% filter(encounter_no_days >= VISITTIMES_THRESHOLD) %>% # still filter out patients that visited hospital infrequently 
    distinct()
#test if using breezing ICD codes will help
#df_glm <- df_glm %>% left_join(patient_withBreazingDifficulties, by = "patient_num") %>% mutate(withAsthmaICDCode = ifelse(is.na(withBreathingDifficuities), "N", withBreathingDifficuities)) %>% select(-withBreathingDifficuities)

#test if using severe asthma ICD codes will help
df_glm <- df_glm %>% left_join(patient_withAcuteAsthma, by = "patient_num") %>% mutate(withAsthmaICDCode = ifelse(is.na(withAcuteAsthma), "N", "Y")) %>% select(-withAcuteAsthma)

glm_X = df_glm %>%  
  mutate(isSevere = as.factor(ifelse(prscbCount >= SEVERITY_THRESHOLD-3, 1, 0))) %>%
  mutate(withAsthmaICDCode = as.factor(ifelse(withAsthmaICDCode == "Y", 1, 0))) %>%
  select(patient_num, encounter_no_days, prscbCount, isSevere, withAsthmaICDCode)

# severity classification
severity_class <- function(x) {
  y <- vector(mode = "numeric", length = length(x))
  y = case_when(
    x <= 1 ~ 0,
    x >1 & x <= 5 ~ 1,
    x > 5 & x < 10 ~ 2,
    x > 10 ~ 3
  )
  return (y)
}

#glm_X = df_glm %>%  
#  mutate(isSevere = as.factor(severity_class(prscbCount))) %>%
#  mutate(withAsthmaICDCode = as.factor(ifelse(withAsthmaICDCode == "Y", 1, 0))) %>%
#  select(patient_num, encounter_no_days, prscbCount, isSevere, withAsthmaICDCode)


glm_Y = df_glm %>% select(9:133)
library(caret)
low_variance <- nearZeroVar(glm_Y)
glm_Y <- glm_Y[,-low_variance]  

glm_p_value <- function(hpo, x = glm_X) {
  target <- as.factor(ifelse(hpo >= 3, 1, ifelse(hpo == 0, 0, 0.5)))
  df <- cbind(x, hpo, target) %>% filter(target == 0 | target == 1)
  df_severe <- df %>% filter(isSevere == 1)
  df_nonSevere <- df %>% filter(isSevere == 0)
  sampled_rows <- sample(1:nrow(df_nonSevere), nrow(df_nonSevere))
  df <- rbind(df_severe, df_nonSevere[sampled_rows,])
  glmmodel <- glm(target ~ isSevere + withAsthmaICDCode, data = df, family = binomial(link = "logit"), maxit = 50)
  return (summary(glmmodel))
}

set.seed(9999)
#l <- list(10)
  tests <- glm_Y %>% map(glm_p_value) %>% map(~.$coefficients)
  result <- data.frame(hpo = names(tests), 
                           `odds ratio_steroid` = round(exp(tests %>% map_dbl(~.[2, 1])), 2),
                           `CI(95%)_steroid` = confid.int(tests %>% map_dbl(~.[2, 1]), 
                                                    tests %>% map_dbl(~.[2, 2])),
                           p_steroid = tests %>% map_dbl(~.[2,4]),
                           `odds ratio_asthma diagnosis` = round(exp(tests %>% map_dbl(~.[3,1])), 2),
                           `CI(95%)_asthma diagnosis` = confid.int(tests %>% map_dbl(~.[3, 1]), 
                                                    tests %>% map_dbl(~.[3, 2])),
                           `p_asthma diagnosis` = tests %>% map_dbl(~.[3,4]))
  
  
  result_logistic <- result %>% arrange(-`odds.ratio_asthma.diagnosis`) 
  write.csv(result_logistic, "./data/logistic_regression.csv", quote = FALSE, row.names = FALSE)
  View(result_logistic)
  
  ggplot(result_logistic) + 
    geom_point(aes(x = odds.ratio_steroid, y = odds.ratio_asthma.diagnosis)) + 
    geom_text(aes(x = odds.ratio_steroid, y = odds.ratio_asthma.diagnosis, label = hpo), data = result_logistic %>% filter(odds.ratio_asthma.diagnosis > 1.1 | odds.ratio_steroid > 5), hjust = -0.1, check_overlap = TRUE) +
    geom_hline(yintercept = 1) + geom_vline(xintercept = 1) + 
    scale_x_continuous(limits = c(0, 15)) +
    theme_bw()
#finalResult <- Reduce("+", l)/length(l)
#finalResult$hpo = l[[1]]$hpo
#finalResult %>% arrange(-estimate.withAsthmaICDCode) %>% filter(p.isSevere < 1, p.withAsthmaICDCode < 1) %>% View()
```



```{r}
ggsave("./data/images/likehood ratio.png", width = 4.5, height = 4.5)
```

## Build a predictive model for asthma severity
The goal of this section is to determine whether HPO terms aggregated from lab tests can be used for medical research with EHR, e.g. machine learning to predict medical outcomes.

### load data 
optional: import data if starting from serialized data
```{r}
library(tidyverse)
df4ML <- read.csv("./data/Hush+_data_matrix.csv", header = TRUE)
noasthmaNoDiabetesNoLiverDamage <- read.csv("./data/patientCombinedCounts_noasthmaNoDiabetesNoLiverDamage.csv", header = TRUE)
asthmaNoDiabetesNoLiverDamage <- read.csv("./data/patientCombinedCounts_asthmaNodiabetesNoLiverDamage.csv", header = TRUE)
joined_data <- asthmaNoDiabetesNoLiverDamage %>% mutate(foldchange_asthma = severePercent/nonSeverePercent, significe_asthma = ifelse(pVal > 0.001, "N", "Y")) %>% select(hpo, foldchange_asthma, significe_asthma) %>% full_join(
  noasthmaNoDiabetesNoLiverDamage  %>% mutate(foldchange_no_asthma = severePercent/nonSeverePercent, significance_no_asthma = ifelse(pVal > 0.001, "N", "Y")) %>% select(hpo, foldchange_no_asthma, significance_no_asthma))
```

### selecte features
We have shown that only a subset of HPO terms are statistically significantly associated with frequent prednisone prescription, i.e. asthma severity. So we only choose those HPO terms for the machine learning task, together with sex, age and encounter number. 
```{r}
# selected HPO terms: statistically significant in either groups-with asthma and without asthma
selectedFeatures <- joined_data %>% filter(significe_asthma == "Y" | significance_no_asthma == "Y")
selectedFeatures <- selectedFeatures$hpo
# only choose records for patients diagnosed with asthma, not diabetes or chronic liver damage
df4ML_filtered <- df4ML %>% filter(withAsthmaICDCode == "Y" & withDiabeteICDCode == "N" & withChronicLiverDamageICDCode == "N")
df4ML_selected <- df4ML_filtered[,c("patient_num","sex_cd", "age", "encounter_no_days",selectedFeatures, "prscbCount")]
#skip feature selection at this step
#Conclusion: it performs worse!
#df4ML_selected <- df4ML_filtered %>% select(patient_num, sex_cd, age, encounter_no_days, everything(), -record_duration, -starts_with("with"))
dim(df4ML_selected)

#factorize sex
df4ML_selected$sex_cd = as.factor(df4ML_selected$sex_cd)
#binarize prednisone prescription to 0 and 1--0 if not severe, 1 if severe
#Important: 
#Since there are more non-severe patients than severe patients, and that we are dropping many non-severe patients to balance the two classes, we will create a more strigent criteria for non-severe patients
#Conclusion: it is not helpful. So switch back by changing the conditions in the ifelse statement
#df4ML_selected <- df4ML_selected %>% mutate(isSevere = ifelse(prscbCount > SEVERITY_THRESHOLD, 1, ifelse(prscbCount <= SEVERITY_THRESHOLD, 0, 0.5))) %>% select(-prscbCount)
df4ML_selected <- df4ML_selected %>% mutate(isSevere = ifelse(prscbCount > SEVERITY_THRESHOLD, 1, 0)) %>% select(-prscbCount)
df4ML_selected$isSevere = as.factor(df4ML_selected$isSevere)

#set patient number of row names
rownames(df4ML_selected) = df4ML_selected$patient_num
df4ML_selected$patient_num = NULL
```

### load libraries
The caret library is used for machine learning. The doSNOW library is used for parallel computation. 
```{r}
require(caret)
require(doSNOW)
require(pROC)
```

### preprocessing 

#### create dummy vars for sex
```{r}
target.index = ncol(df4ML_selected)
dmy <- dummyVars(~ ., data = df4ML_selected[,-target.index]) # only sex_cd column is factor
df4ML_dmy <- predict(dmy, df4ML_selected[,-target.index])
```

#### Impute missing age. We could omit rows with missing age as well. 
```{r}
impute <- preProcess(as.data.frame(df4ML_dmy), method = "bagImpute")
df4ML_dmy_imputed <- predict(impute, df4ML_dmy)
#df4ML_dmy <- df4ML_dmy_imputed
#df4ML_dmy <- as.data.frame(df4ML_dmy)
df4ML_dmy_imputed <- as.data.frame(df4ML_dmy_imputed)
df4ML_dmy_imputed$isSevere <- df4ML_selected$isSevere   #add back the prediction target
```

### data partation
partation data into training and testing, ratio = 0.7
```{r}
indexes <- createDataPartition(df4ML_dmy_imputed$isSevere, p = 0.7, list = FALSE)
training <- df4ML_dmy_imputed[indexes,]
#remove intermediant patients
training <- training %>% filter(isSevere == 0 | isSevere == 1)
testing <- df4ML_dmy_imputed[-indexes,]
#change back intermediant patients to non-severe patients
testing$isSevere[testing$isSevere == 0.5] = 0 
```
optional: binarize the encounter days
```{r}
#training$encounter_no_days <- ifelse(training$encounter_no_days > VISITTIMES_THRESHOLD, 1, 0)
#testing$encounter_no_days <- ifelse(testing$encounter_no_days > VISITTIMES_THRESHOLD, 1, 0)
```

remove features that have "almost" zero variations.
```{r}
nearZeroFeatures <- nearZeroVar(training)
training <- training[,-nearZeroFeatures]
testing <- testing[,-nearZeroFeatures]
train_pos <- training[training$isSevere==1,]
train_neg <- training[training$isSevere==0,]
pos_size = nrow(train_pos)
neg_size = nrow(train_neg)
```

To address class imbalance problem (severe:nonsevere ~ 1:11), we tried two method: 
1. resample severe patients so that the number of severe patients matches non-severe patients. The caveate is that we added a lot of duplications.
2. sample the non-severe class to only choose a subset (equal size to severe patients). The caveate is that we dropped many samples. 

The initial trial indicated that the second method works better.
```{r}
#only select same number of negative controls
train_neg_sample <- train_neg[sample(1:neg_size, pos_size),]
training <- rbind(train_pos, train_neg_sample)
#add positive controls--not as good as the last solution
#train_pos_expand <- train_pos[sample(1:pos_size, neg_size, replace = TRUE),]
#training <- rbind(train_pos_expand, train_neg)

training$isSevere <- make.names(training$isSevere)
testing$isSevere <- make.names(testing$isSevere)
training$isSevere <- as.factor(training$isSevere)
testing$isSevere <- as.factor(testing$isSevere)
```

### build a model

#### first test a linear model
The Baysian Generalized Linear model is simple to use. So we tested this as our first step. This model does not have parameters to tune, so we just used cross validation (10 folds, 3 repeats)
```{r}
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3, savePredictions = TRUE, classProbs = TRUE)
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
bayesglm <- train(training[,-target.index], training$isSevere, method = "bayesglm", trControl = train.ctrl, preProcess = c("center","scale", "YeoJohnson"))
stopCluster(c1)
prediction <- predict(bayesglm, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm


```

The result is not quite good. We only have 11.9% recall. We try a method with boosting. 
```{r}
library(mboost)
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3, verboseIter = TRUE)
#tune.grid = expand.grid(prune = c("no"), mstop = seq(20, 100, 1))
#this is the best hyperparameters
tune.grid = expand.grid(prune = c("no"), mstop = c(30))
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
#mstop = 150, prune = "no"
glmboost <- train(training[,-target.index], training$isSevere, method = "glmboost", trControl = train.ctrl, tuneGrid = tune.grid, preProcess = c("center","scale", "YeoJohnson"))
stopCluster(c1)
prediction <- predict(glmboost, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm
```
another boosting method
```{r}
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3)
tune.grid = expand.grid(trials = 20, model = c("tree"), winnow = FALSE)
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
C50 <- train(training[,-target.index], training$isSevere, method = "C5.0", trControl = train.ctrl, tuneLength = 5, preProcess = c("center","scale", "YeoJohnson"))
stopCluster(c1)
prediction <- predict(C50, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm
```
The gradient boosting methods are the winners so far.
```{r}
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3)
#tune.grid = expand.grid(prune = c("no"), mstop = seq(20, 100, 1))
#this is the best hyperparameters
#tune.grid = expand.grid(n.trees = 200, interaction.depth = 1, shrinkage = 0.1, n.minobsinnode = 10)
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
#mstop = 150, prune = "no"
gbm <- train(training[,-target.index], training$isSevere, method = "gbm", trControl = train.ctrl, tuneLength = 5, preProcess = c("center","scale", "YeoJohnson"))
stopCluster(c1)
prediction <- predict(gbm, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm
```
```{r}
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3, classProbs = TRUE)
#tune.grid = expand.grid(prune = c("no"), mstop = seq(20, 100, 1))
#this is the best hyperparameters
#tune.grid = expand.grid(n.trees = 200, interaction.depth = 1, shrinkage = 0.1, n.minobsinnode = 10)
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
#mstop = 150, prune = "no"
xgboost <- train(training[,-target.index], training$isSevere, method = "xgbTree", trControl = train.ctrl, tuneLength = 5, preProcess = c("center","scale", "YeoJohnson"))
stopCluster(c1)
prediction <- predict(xgboost, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm
prediction <- predict(xgboost, testing[,-target.index], type = "prob")
require(pROC)
roc1 <- roc(testing$isSevere, prediction$X1, smooth = TRUE)
data.frame(sensitivity = roc1$sensitivities, specificity = roc1$specificities) %>% ggplot() + geom_point(aes(1-specificity, sensitivity), size = 0.5) + xlab("false positive rate") + ylab("true positive rate")
```

Try random forest
```{r}
train.ctrl.rf = trainControl(method = "repeatedcv", number = 10, repeats = 3, savePredictions = T, search = "grid")
tunegrid <- expand.grid(.mtry = c(10))
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
target.index = ncol(training)
# one can specify ntree = 300, but default works equally well
rf <- train(training[,-target.index], training$isSevere, method = "rf", trControl = train.ctrl.rf, tuneGrid = tunegrid, preProcess = c("center","scale", "YeoJohnson"))
stopCluster(c1)
rf
prediction <- predict(rf, testing[,-target.index])
confusionMatrix(prediction, testing$isSevere)


```

try svm
```{r}
#folds = 3
#cvIndex <- createFolds(training$isSevere, folds, returnTrain = TRUE)
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3)
#train.ctrl = trainControl(method = "none")
tune.grid <- expand.grid(sigma = c(0.1872799), C = c(2))
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
svmRadial <- train(isSevere ~., data = training, method = "svmRadial", trControl = train.ctrl, tuneGrid = tune.grid, preProcess = c("center", "scale", "YeoJohnson"))
stopCluster(c1)
prediction <- predict(svmRadial, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm
```
Try another SVM
```{r}
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary)
#best: 3, 0.01, 1
tune.grid <- expand.grid(degree=2:4, scale = c(0.001, 0.01, 0.1, 1), C = c(0.1, 1, 10))
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
svmPoly <- train(isSevere ~., data = training, method = "svmPoly", trControl = train.ctrl, tuneGrid = tune.grid, preProcess = c("center", "scale", "YeoJohnson"))
stopCluster(c1)
prediction <- predict(svmPoly, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm
```

try neural network
```{r}
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3)
#tune.grid <- expand.grid(size=10, decay=c(0.00001, 0.0001, 0.0005, 0.001))
tune.grid <- expand.grid(layer1 = c(15, 20, 25), layer2 = c(8, 10, 15), layer3 = c(4, 6, 8))
# best
#tune.grid <- expand.grid(layer1 = 25, layer2 = 10, layer3 = 8)
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
nnet <- train(isSevere ~., data = training, method = "mlpML", preProcess = c("center", "scale", "YeoJohnson"), trControl = train.ctrl, tuneGrid = tune.grid)
stopCluster(c1)
prediction <- predict(nnet, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm

```

try naive bayes
```{r}
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3, savePredictions = TRUE, classProbs = TRUE)
#0, FALSE, 1
tune.grid = expand.grid(laplace = 0:3, usekernel = FALSE, adjust = 1:3)
target.index = ncol(training)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
naive_bayes <- train(training[,-target.index], training$isSevere, method = "naive_bayes", trControl = train.ctrl, tuneLength = 10, preProcess = c("center", "scale", "YeoJohnson"))
#naive_bayes <- train(training[,-target.index], training$isSevere, method = "naive_bayes", trControl = train.ctrl, tuneLength = 10)
stopCluster(c1)
prediction <- predict(naive_bayes, testing[,-target.index])
cm <- confusionMatrix(prediction, testing$isSevere)
cm
```

Test whether ensemble works better than any one of them. 
```{r}
require(caretEnsemble)
train.ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3, savePredictions = "final", classProbs = TRUE)
target.index = ncol(training)
alg_list <- c("bayesglm", "glmboost", "C5.0", "gbm", "rf", "svmRadial", "svmPoly", "mlpML", "xgbTree" )
#folds = 3
#cvIndex <- createFolds(training$isSevere, folds, returnTrain = TRUE)
tuneSettings <- list(
  glmboost = caretModelSpec(method = "glmboost", tune.grid = expand.grid(prune = c("no"), mstop = c(30))),
  c50 = caretModelSpec(method = "C5.0", tuneLength = 5),
  gbm = caretModelSpec(method = "gbm", tuneLength = 5 ),
  rf = caretModelSpec(method = "rf", tunegrid <- expand.grid(.mtry = c(10))),
  svmRadial = caretModelSpec(method = "svmRadial", tune.grid <- expand.grid(sigma = c(0.1872799), C = c(2))),
  svmPoly = caretModelSpec(method = "svmPoly", tune.grid <- expand.grid(degree=2:4, scale = c(0.001, 0.01, 0.1, 1), C = c(0.1, 1, 10))),
  mlpML = caretModelSpec(method = "mlpML", tune.grid <- expand.grid(layer1 = c(15, 20, 25), layer2 = c(8, 10, 15), layer3 = c(4, 6, 8))),
  xgbtree = caretModelSpec(method = "xgbTree", tuneLength = 5)
)
c1 <- makeCluster(3, type = "SOCK")
registerDoSNOW(c1)
models_ensemble <- caretList(training[,-target.index], training$isSevere, preProcess = c("center", "scale", "YeoJohnson"), trControl = train.ctrl, methodList = alg_list, tuneList = tuneSettings, continue_on_fail = TRUE)
#naive_bayes <- train(training[,-target.index], training$isSevere, method = "naive_bayes", trControl = train.ctrl, tuneLength = 10)
prediction <- predict(models_ensemble, testing[,-target.index])
poll <- vector(mode = "character")
p_threshold = 0.73
prediction = prediction[,c("C5.0", "gbm", "bayesglm", "glmboost", "rf", "svmRadial", "svmPoly", "mlpML", "xgbTree")]
for (i in 1:nrow(prediction)) {
  #poll[i] = ifelse(mean(prediction[i,] > p_threshold), "X1", "X0")
  poll[i] = ifelse(sum(prediction[i,] == "X1") >= ncol(prediction)/2, "X1", "X0")
}
#cm <- confusionMatrix(as.factor(poll), testing$isSevere)
#cm
stack.train.ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
stack.rf <- caretStack(models_ensemble, method = "rf", trControl = stack.train.ctrl)
stopCluster(c1)
#calculate ROC and AUC
prob4roc = cbind(as.data.frame(prediction), isSevere = testing$isSevere)
rocs <- list()
aucs <- list()
for(i in 1:ncol(prediction)) {
  rocs[[i]] <- roc(prob4roc$isSevere, prob4roc[,i], smooth = TRUE)
  aucs[[i]] = rocs[[i]]$auc
}
names(rocs) = colnames(prediction)
names(aucs) = colnames(prediction)
print(unlist(aucs))

aucs_text = "Area under curve:"
for (i in 1:length(aucs)) {
  aucs_text = paste(c(aucs_text, paste(c(toString(names(aucs[i]), width = 10), toString(round(aucs[[i]], 3))), collapse = ": ")), collapse = "\n")
}
print(toString(aucs_text))
#plot the roc for xgbTree
roc_data = data.frame(FPP = vector(mode = "double"), TPP = vector(mode = "double"), model_names = vector(mode = "character"))
for (i in 1:length(rocs)) {
  model_name = names(rocs[i])
  print(model_name)
  specificities = rocs[[i]]$specificities
  sensitivies = rocs[[i]]$sensitivities
  roc_data <- rbind(roc_data,  data.frame(FPP = 1- specificities, TPP = sensitivies, model_names=rep(model_name, length(specificities))))
}
ggplot(roc_data) + geom_line(aes(x = FPP, y = TPP, color = model_names, group = model_names)) + annotate("text", x = 0.5, y = 0.5, label = aucs_text) +
  xlab("false positive rate") + ylab("true positive rate") +
  theme_bw() + theme(panel.grid = element_blank())
```
The result suggests that simplying polling different models does not improve prediction. @TODO: what is the correct way to use multiple models?


Look visualize patients. Plot patients based on their HPO terms (do a PCA first), look at whether severe and nonsevere patients are placed at different regions
```{r}
data_cluster <- df4ML_dmy_imputed 
#data_cluster <- data_cluster %>% mutate(encounter_no_days = ifelse(encounter_no_days > VISITTIMES_THRESHOLD, 1, 0))

k_cluster <- kmeans(data_cluster[,5:41], centers = 6, nstart = 4)
data_clustered <- data_cluster %>% mutate(k_means_cluster = k_cluster$cluster)
require(pcaPP)
require(caret)
preprocess <- preProcess(data_cluster[,c(5:41)], method = c("center", "scale", "YeoJohnson"))
data_cluster_transformed <- predict(preprocess, newdata = data_cluster)
data_cluster_2d <- PCAgrid(data_cluster_transformed[,c(5:41)], k = 2, scores = TRUE)
cluster_pca <- cbind(data_clustered, data_cluster_2d$scores)
#data_cluster_2d <- prcomp(data_cluster_transformed[,c(5:41)], scale. = TRUE, rank. = 2)
#cluster_pca <- cbind(data_clustered, data_cluster_2d$x)
ggplot(cluster_pca) + geom_point(aes(x = Comp.1, y = Comp.2, color = as.factor(isSevere), shape = as.factor(isSevere)), size = 1.3,  alpha = 0.6) +
  scale_shape_manual(name = "isSevere", values = c(20, 5)) + scale_color_manual(name = "isSevere",breaks = c(0, 1), values = c("deepskyblue", "red")) +
  xlab("PC1") + ylab("PC2") +
  theme_bw() + theme(panel.grid = element_blank())
```
It defintely looks that severe patients are preferentially clustered on the right hand side.

```{r}
cluster_pca %>% mutate(Eosinophilia = ifelse(Eosinophilia >= 2, 2, Eosinophilia)) %>%
ggplot() + geom_point(aes(x = Comp.1, y = Comp.2, color = as.factor(Eosinophilia), shape = as.factor(isSevere)), size = 1.3,  alpha = 1) + scale_color_brewer(name = "Eosinophilia Freq", palette = 3, breaks = c(0, 1, 2), labels = c("0", "1", ">=2")) + scale_shape_manual(name = "isSevere", values = c(15, 4), breaks = c(0, 1), labels = c("No", "Yes")) +
  xlab("PC1") + ylab("PC2") +
  theme_bw() + theme(panel.grid = element_blank())

scale_fill_manual(name = "Eosinophilia",breaks = c(0, 1), values = c("deepskyblue", "red")) +scale_shape_manual(name = "isSevere", values = c(15, 4)) +scale_color_gradientn(name = "Eosinophilia Freq", breaks = c(0, 1, 2), labels = c("0", "1", ">=2"), colors = c("blue", "white","magenta"), space = "Lab")
```


Let's aggregate patients into each tile and plot the heatmap of ratios between severe vs nonsevere patients
```{r}
densityData <- cluster_pca %>% mutate(comp1 = round(Comp.1 * 2, 0)/2, comp2 = round(Comp.2 * 2, 0)/2) %>% group_by(isSevere, comp1, comp2) %>% summarize (count = n()) %>% ungroup() %>% mutate(isSevere = make.names(isSevere)) %>% spread(key = isSevere, value = count, fill = 0) %>% mutate(severeCount = X1, nonSevereCount = X0) %>% select(-X0, -X1)

densityData %>% filter(severeCount>=0 & nonSevereCount>=2) %>% ggplot() + 
  geom_tile(aes(x = comp1, y = comp2, fill = severeCount/nonSevereCount)) +  
  scale_fill_distiller(name = "ratio of counts = \nsevere/nonsevere", palette = "Spectral") + 
  xlab("PC1") + ylab("PC2") +
  theme_bw() + theme(panel.grid = element_blank())
```

```{r}
densityData %>% filter(severeCount>=0 & nonSevereCount>=2) %>% ggplot() + 
  geom_tile(aes(x = comp1, y = comp2, fill = severeCount/nonSevereCount)) + 
  scale_fill_gradientn(name = "ratio of counts = \nsevere/nonsevere", breaks = c(0, 0.5, 1), colors = c("blue", "white","magenta"), space = "Lab")+ 
  xlab("PC1") + ylab("PC2") +
  theme_bw() + theme(panel.grid = element_blank())
```

Result: there are differences of HPO terms between severe and non severe asthma patients. This is the basis for doing the statistical testing. 


calculate some initial statistics of patient cohort
sex of patients:
```{r}
patients %>% select(patient_num, sex_cd) %>% distinct() %>% group_by(sex_cd) %>% summarise(count = n()) %>% ungroup() %>% mutate(fraction = count/sum(count))
```
distribution of patients by age:
```{r}
df4ML$age %>% na.omit() %>% quantile()
df4ML$age %>% na.omit() %>% hist()
ggplot(df4ML) + geom_histogram(aes(x = age, group = sex_cd), position = "dodge")

# define the binwidth
BINWIDTH = 10
data_pyramid <- df4ML %>% select(patient_num, age, sex_cd) %>% 
  distinct() %>%
  mutate(cat = as.factor(round(age/BINWIDTH, 0) + 1)) %>%
  group_by(sex_cd, cat) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  mutate(count = ifelse(sex_cd == "M", -count, count))
  
data_pyramid %>% na.omit() %>% 
  ggplot() +
  geom_bar(aes(x = cat, y = count, fill = sex_cd), stat = "identity") + 
  scale_x_discrete(breaks = seq(2, 10, 2), labels = seq(2,10,2) * BINWIDTH) +
  scale_y_continuous(breaks = seq(-2000, 2000, by = 1000), labels = c(2000, 1000, 0, 1000, 2000)/1000, limits = c(-2000, 2000)) +
  scale_fill_manual(name = "gender", values = c(M = "royalblue", F = "lightcoral"), breaks = c("M", "F"), labels = c("male", "female")) + xlab("age (years)") + ylab("count (x1,000)") +
  coord_flip() + theme_bw() + theme(panel.grid = element_blank(), legend.position = "none", axis.title = element_text(size = 8), axis.text = element_text(size = 8), legend.text = element_text(size = 8), legend.title = element_text(size = 10))

ggsave("./data/images/patient_sex_age_distribution.png", width = 2, height = 1.5)
```

```{r}
patientPartation <- patients %>% left_join(patient_withAsthmaICD, by = "patient_num") %>% mutate(withAsthmaICDCode = replace_na(withAsthmaICDCode, "N")) %>% 
  distinct() %>%
  group_by(withAsthmaICDCode) %>%
  summarise(count = n()) %>% ungroup() 
patientPartation %>%
  ggplot() + geom_bar(aes(x = 1, y = count, fill = withAsthmaICDCode), color = "black", stat = "identity", position = "stack") + xlab("") + ylab("") + 
  scale_fill_manual(values = c(N = "white", Y = "black"), breaks = c("N", "Y")) +
  theme_bw() + theme(panel.grid = element_blank(), legend.position = "none", panel.border = element_blank(), axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank()) 

ggsave("./data/images/asthma_code_partation.png", width = 1, height = 4)
```

```{r}
diagnosisCodesForAsthmaAndNonAsthma <- allDiagnosisCodesForAsthmaPatients %>% transmute(icd, asthma = count) %>% full_join(
  allDiagnosisCodesForNonAsthmaPatients %>% transmute(icd, nonAsthma = count), by = "icd"
) %>%
  mutate(asthma = replace_na(asthma, 0), nonAsthma = replace_na(nonAsthma, 0)) %>% left_join(icd_3_digit_code_annotation, by = "icd")
originalLabel = diagnosisCodesForAsthmaAndNonAsthma[1:30,]$icd
newLabel = diagnosisCodesForAsthmaAndNonAsthma[1:30,]$descr
diagnosisCodesForAsthmaAndNonAsthma[1:30,] %>% 
  mutate(icd = factor(icd, rev(reorder(icd, asthma))), asthma = asthma/patientPartation$count[2], nonAsthma = nonAsthma/patientPartation$count[1]) %>%
  gather(asthma, nonAsthma, key = "asthma", value = "fraction") %>% filter(descr != "Asthma") %>%
  ggplot() + geom_tile(aes(x = asthma, y = icd, fill = fraction)) + scale_y_discrete(breaks = originalLabel, labels = newLabel) +
  xlab("") + ylab("") +
  scale_fill_gradient2(low = "blue", mid = "white",
  high = "magenta", midpoint = 0.6) + 
  theme_bw() + theme(panel.grid = element_blank(), axis.title = element_text(size = 8), axis.text = element_text(size = 8), legend.text = element_text(size = 8), legend.title = element_text(size = 10), panel.border = element_blank())

ggsave("./data/images/otherICDcodes.png", width = 8, height = 5)
  
```


track time
```{r}
df4ML$record_duration %>% median()
```


Disconnect database
```{r}
dbDisconnect(db)
```



